\chapter{INTRODUCTION}
\label{intro}



\section{Problem Statement}

Networking architecture has become the focus of many facets in computing
with the increased reliance on data. As more and more devices become connected
and users consume and generate data at an ever-increasing rate, the way we
accomodate these changes in networking infrastructure has prompted the need
for change. The conventional network switch is a fairly static, rigid device
that utilizes two primary components, a control plane and data plane. In a
network switch the control plane is responsible for the configuration and
management of the data plane. Whereas the data plane is responsible for routing
network traffic through a switch, also known as the forwarding path. These
components have long been tightly coupled, where the control plane configures 
the forwarding path at boot time and relies on configuration scripts and
settings to orchestrate the applications, the network data they operate on, 
and the physical resources available. This model has been sustainable, but is 
quickly becoming a major roadblock in the evolution of networking switches. 
For example, in a large data center, any downtime results in a loss of revenue 
and the goal is to minimize the amount of time spent rebooting and
reconfiguring switches as much as possible. The reason for this management
model is due to the fact that data planes themselves lack the ability to be
programmable, that is, they are not reactive. Forwarding decisions for packets
rely on matching tables that map network traffic flows to some desired 
behavior. These match tables are defined and managed by the control plane, but
used by the data plane. When a table modification is needed, the control and
data planes must be torn down and rebuilt to reflect the changes made. In
order to overcome this hurdle control and data planes need to be programmable.

Software Defined Networking (SDN) provides a framework to address the
problems with conventional networking switches by introducing abstractions
to help describe the major components of networking devices. The most prominent
standard in this new networking paradigm is the OpenFlow (OF) [ref] protocol,
which loosens the grip the control plane has over the forwarding plane by 
viewing the data plane as an abstract machine. The abstraction describes the 
forwarding path as a packet processing machine, capable of receiving,
processing, and forwarding packets that enter a networking device. The two 
components communicate through a messaging protocol to relay information. This
protocol serves as an application binary interface (ABI) for network switch 
applications by providing a north-bound interface to the control plane, and a 
south-bound interface to the data plane.

Even with the establishment of an abstract packet processing machine, there
is still exist numerous problems with respect to programmability. The abstract 
machine identifies the necessary components needed to procure the desired 
functionality, but gives no standard model to program against. Network switch
vendors do not have to conform to any ``standard'' when manufacturing these
devices, and as a result there is a vast amount of proprietary hardware that
varies greatly between them. These proprietary components include hardware 
accelerators for particular network processing functions, such as validation 
(checksums), security (encryption/decryption), and packet processing (header
decoders, matching tables, FPGAs). Though these capabilites are generally 
available in most devices, their implementation is unclear. Parts of this 
functionality is handled in software, whereas others are offloaded at runtime 
to more well suited hardware components. The documentation for programming 
against these devices is sparse at best, and only adds the difficulties in 
attempts to accurately model how a networking application can be targeted to 
native hardware.

From all of these problems emerges the need for network switch applications
that can configure the control plane and also utilize the full potential of 
the underlying hardware available to the data plane. Currently there exists
no standard language capable of producing applications that address both of
these problem sets, yet this functionality is becoming highly desireable.
Reliance on vendor applications to fulfill the needs of an increasing customer
base breeds a sort of stagnation, where users must wait until a manufacturer
provides the flexibility and functionality desired. Generic end-user
applications rarely satisfy \emph{all} of the needs of a particular consumer, 
and the ability to create customized applications that perform efficiently 
would allow for users to build something that works for \emph{them}. This 
concept is akin to the creation of user applications for general purpose 
computing devices, CPUs, which support a large set of higher level languages 
that can be lowered to a well-defined interface that can utilize the 
capabilities and features present in a general purpose machine. In order to
create said customized networking applications, networking devices need to be
more open and programmable.

Though there exist numerous general purpose high level programming languages
that provide constructs and abstractions in order to create applications for
general purpose machines, there exist very few that attempt to tackle the
problem of providing basic networking programming requirements. Network
programming languages build on a primitive instruction set architectures,
(ISAs), that provide arithmetic, logical, and control flow instructions.
However in order to fulfill the requirements of the network programming domain
they need to accomodate networking constructs such as protocol headers and 
match tables. 

Protocol headers vary greatly, and the language must provide the means to 
represent and extract the fields within these headers efficiently. The main 
issue with protocol header extraction is that many of these fields do not 
align to standard ISA word sizes [refs], that is, they tend to not be byte 
(8-bit) aligned. Fields can be contained in 2-bit (e.g. Ethernet Type) or even 
48-bit regions (e.g. Ethernet MAC addresses). The same issue arises in the case
of matching tables, where the key used to identify entries in the table 
generally has a size equal to size of fields in a header.

It is clear that traditional networking methods are nearing the end of their
sustainability, and that there is a need to evolve networking infrastructure
into something that is more well suited for the current and future needs of
consumers. Networking infrastructure needs to be more flexible, and allow 
network administrators to shape and mold their systems based on their
particular needs. In order to achieve this next step there is a need for a
high level programming language that supports networking constructs and
a native architecture that can implement the needs of the language. This
architecture must provide the physical and logical resources required by
applications through an ABI, allowing developers to program against a much
more concrete networking device.

\section{Goals}
It becomes clear that there is a need for a high level programming language 
that supported extensions into the domain of network programming. The language 
needs to be flexible enough to accomodate common programming language features 
and networking domain specific concepts, but also provide safety guarantees to 
curtail undefined behavior, as much as possible, and produce well formed 
applications. Also the language needs to allow the programmer to define 
behavior across both components in a switch, the control and data planes. This 
also helped define the requirements of the target machine for these networking 
applications. The runtime needs to be fully programmable and execute these 
programs on native hardware. By utilizing a virtual machine as the execution 
environment, the runtime is able to be mapped to a variety of architectures 
and take advantage of any and all hardware optimizations present.

\section{Contributions}
Freeflow is our software implementation of an intelligent network switch. This 
system provides a framework on which compiled network applications can be 
loaded and executed. The system has two major components needed by 
applications, a runtime environment to target which we call the Freeflow 
Virtual Machine (FFVM), and a system interface which applications can be 
programmed against. 

\subsection{Virtual Machine}
FFVM is a process that provides the resources necessary for network
applications to execute. These resources are:

\begin{itemize}
\item \emph{Ports} - The source of I/O for applications.
\item \emph{Tables} - Matching data structures that define forwarding behavior.
\item \emph{Packet Context} - Contextual information about a packet.
\item \emph{Action Exection} - Native FFVM instructions to be executed by the runtime.
\item \emph{Memory} - Packet Context buffers.
\item \emph{Threading} - Infrastructure for modeling applications in various threading architectures.
\end{itemize}

\subsection{Runtime Support Library}
Freeflow provides a runtime support library that Steve applications can leverage to execute as efficiently as possible. The library houses a collection
of system calls, exposed as external C functions, to allow applications to call
into the system during execution.

\section{Background}
Throughout the development of this project there were a few implementation
methods that did not end up panning out. Each approach has their own pros
and cons, and are highlighted in the follow sections.

\subsection{DPDK}
Intel's DPDK provided users with a framework on which data plane applications
could be built utilizing highly optimized constructs and device drivers. The
examples laid out in the documentation is promising, and the desire to have
low level access to underlying hardware in a system is more than satisfied
in this impelementation. However, there were a few road blocks on the path to
embracing this powerful data plane runtime environment. First and foremost, the
device drivers provided were specifically written for Intel brand hardware. If
there is no genuine Intel network inferface cards (NICs), a virtual machine
would be necessary in order to emulate their functionality and be able to take
advantage of the low level functionality, such as direct access to raw 
ethernet packet data. At the time we were investigating this approach, DPDK was
more in it's infancy (release 1.0, 1.1), and though there was a decent amount 
of documentation, the usage of their system was not very intuitive. Lastly 
there was the issue of language support, DPDK can only build C applications 
using GCC as C++ support is only available with the usage of Intel's C++ 
compiler. The combination of all these issues led us to stray away from 
targeting DPDK as our runtime environment.

\subsection{RISC V}
Our next approach focused more on the interaction between the language and 
runtime components of our system, with the hopes of being able to execute
the language in a native ISA. We came across an extensible ISA, RISC V, that
provided not only basic arithmetic, logical, and control flow instructions but
also left room for a number of custom instructions. This seemed like a great
way to incorporate specialized network programming instructions into a native
format. Unfortionately, this would also require that we interpret and implement
all of the supported instructions in the set in an virtual machine. As a result
the execution took a serious hit in terms of performance at the cost of this
flexibility. This project requires a fine balance of flexibility and 
performance, and the deviation between these properties was too great.